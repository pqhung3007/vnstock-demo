# 04. Ph√¢n T√≠ch Xu H∆∞·ªõng & Keyword

> ‚ö†Ô∏è **L∆ØU √ù QUAN TR·ªåNG:** TrendingAnalyzer hi·ªán **KH√îNG ƒë∆∞·ª£c export** trong package ch√≠nh v√† API th·ª±c t·∫ø **KH√ÅC** v·ªõi t√†i li·ªáu n√†y. 
> 
> T√†i li·ªáu n√†y ch·ªâ mang t√≠nh **THAM KH·∫¢O** cho t√≠nh nƒÉng s·∫Ω c√≥ trong t∆∞∆°ng lai ho·∫∑c b·∫°n c·∫ßn t·ª± implement d·ª±a tr√™n c√°c c√¥ng c·ª• ph√¢n t√≠ch text kh√°c.

---

## 1. TrendingAnalyzer - Kh√°i Ni·ªám & API Th·ª±c T·∫ø

### TrendingAnalyzer L√† G√¨?

`TrendingAnalyzer` l√† c√¥ng c·ª• n·ªôi b·ªô ƒë·ªÉ ph√¢n t√≠ch xu h∆∞·ªõng tin t·ª©c d·ª±a tr√™n n-grams.

### ‚ö†Ô∏è API Th·ª±c T·∫ø (Kh√°c v·ªõi t√†i li·ªáu c≈©)

**Import (kh√¥ng ph·∫£i t·ª´ package ch√≠nh):**
```python
# KH√îNG th·ªÉ: from vnstock_news import TrendingAnalyzer
# Ph·∫£i d√πng:
from vnstock_news.trending.analyzer import TrendingAnalyzer
```

**Kh·ªüi t·∫°o:**
```python
analyzer = TrendingAnalyzer(
    stop_words_file="path/to/stopwords.txt",  # Optional
    min_token_length=3                         # Minimum token length
)
```

**Parameters:**
- `stop_words_file` (str, optional): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file stopwords
- `min_token_length` (int): ƒê·ªô d√†i t·ªëi thi·ªÉu c·ªßa token (default: 3)

### ‚ö†Ô∏è C√°c Method Th·ª±c T·∫ø

#### 1. `update_trends(text, ngram_range=None)`

C·∫≠p nh·∫≠t trending counter v·ªõi text m·ªõi.

```python
analyzer = TrendingAnalyzer()

# C·∫≠p nh·∫≠t t·ª´ nhi·ªÅu text
texts = ["Ch·ª©ng kho√°n tƒÉng m·∫°nh", "Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n h√¥m nay"]

for text in texts:
    analyzer.update_trends(text, ngram_range=[2, 3, 4, 5])
```

#### 2. `get_top_trends(top_n=20)`

L·∫•y top trending phrases.

```python
# Sau khi update_trends
top_trends = analyzer.get_top_trends(top_n=10)

print(top_trends)
# {'ch·ª©ng kho√°n tƒÉng': 5, 'th·ªã tr∆∞·ªùng ch·ª©ng': 3, ...}
```

#### 3. `reset_trends()`

Reset counter v·ªÅ 0.

```python
analyzer.reset_trends()
```

---

## 2. C√°c Method KH√îNG T·ªìn T·∫°i ‚ùå

Nh·ªØng method n√†y **KH√îNG c√≥** trong m√£ ngu·ªìn th·ª±c t·∫ø:

- ‚ùå `extract_keywords(texts, top_n)` - KH√îNG T·ªíN T·∫†I
- ‚ùå `extract_topics(articles_df, content_column, top_n)` - KH√îNG T·ªíN T·∫†I  
- ‚ùå `get_trending(articles_df, time_window, top_n)` - KH√îNG T·ªíN T·∫†I
- ‚ùå `analyze_sentiment(texts)` - KH√îNG T·ªíN T·∫†I

---

## 3. Workflow Th·ª±c T·∫ø (D√πng API C√≥ S·∫µn)

---

## 3. Workflow Th·ª±c T·∫ø (D√πng API C√≥ S·∫µn)

### V√≠ D·ª•: Ph√¢n T√≠ch Trending V·ªõi API Th·∫≠t

```python
from vnstock_news.trending.analyzer import TrendingAnalyzer
from vnstock_news import Crawler
import pandas as pd

# B∆∞·ªõc 1: L·∫•y tin t·ª©c
crawler = Crawler(site_name="vnexpress")
articles = crawler.get_articles_from_feed(limit_per_feed=30)

# B∆∞·ªõc 2: Kh·ªüi t·∫°o analyzer
analyzer = TrendingAnalyzer(min_token_length=3)

# B∆∞·ªõc 3: C·∫≠p nh·∫≠t trends t·ª´ng text
for article in articles:
    title = article.get('title', '')
    description = article.get('description', '')
    full_text = f"{title} {description}"
    
    # Update v·ªõi n-grams 2,3,4,5
    analyzer.update_trends(full_text, ngram_range=[2, 3, 4, 5])

# B∆∞·ªõc 4: L·∫•y top trending
top_trends = analyzer.get_top_trends(top_n=20)

print("üî• Top Trending Phrases:")
for i, (phrase, count) in enumerate(top_trends.items(), 1):
    print(f"{i:2d}. {phrase:30s} - {count:3d} l·∫ßn")
```

**Output:**
```
üî• Top Trending Phrases:
 1. ch·ª©ng kho√°n tƒÉng             -  15 l·∫ßn
 2. th·ªã tr∆∞·ªùng h√¥m                -  12 l·∫ßn
 3. nh√† ƒë·∫ßu t∆∞                    -  10 l·∫ßn
...
```

---

## 4. Gi·∫£i Ph√°p Thay Th·∫ø Cho Keyword Extraction

V√¨ API th·ª±c t·∫ø kh√°c v·ªõi t√†i li·ªáu c≈©, ƒë√¢y l√† c√°ch t·ª± implement keyword extraction:

### Option 1: D√πng Collections.Counter

```python
from collections import Counter
from vnstock_news import Crawler
import re
import pandas as pd

# L·∫•y tin t·ª©c
crawler = Crawler(site_name="vnexpress")
articles = crawler.get_articles_from_feed(limit_per_feed=50)

# Extract t·∫•t c·∫£ t·ª´
all_words = []
for article in articles:
    title = article.get('title', '')
    # T√°ch t·ª´ ƒë∆°n gi·∫£n
    words = re.findall(r'\w+', title.lower())
    # L·ªçc t·ª´ c√≥ √≠t nh·∫•t 3 k√Ω t·ª±
    words = [w for w in words if len(w) >= 3]
    all_words.extend(words)

# ƒê·∫øm t·∫ßn su·∫•t
word_freq = Counter(all_words)

# Top 20 keywords
top_keywords = dict(word_freq.most_common(20))

print("üî• Top Keywords:")
for word, count in top_keywords.items():
    print(f"{word:20s}: {count}")
```

### Option 2: D√πng Pandas

```python
from vnstock_news import Crawler
import pandas as pd
import re

crawler = Crawler(site_name="vnexpress")
articles = crawler.get_articles_from_feed(limit_per_feed=50)

# Convert to DataFrame
df = pd.DataFrame(articles)

# Extract keywords t·ª´ title
def extract_words(text):
    if not text:
        return []
    words = re.findall(r'\w+', text.lower())
    return [w for w in words if len(w) >= 3]

df['keywords'] = df['title'].apply(extract_words)

# Flatten v√† ƒë·∫øm
all_keywords = [word for keywords in df['keywords'] for word in keywords]
keyword_counts = pd.Series(all_keywords).value_counts().head(20)

print(keyword_counts)
```

---

## 5. Best Practices & Tips

---

## 5. Best Practices & Tips

1. **S·ª≠ d·ª•ng TrendingAnalyzer th·ª±c t·∫ø:**
   ```python
   from vnstock_news.trending.analyzer import TrendingAnalyzer  # ƒê√∫ng
   # KH√îNG: from vnstock_news import TrendingAnalyzer
   ```

2. **Update trends t·ª´ng text m·ªôt:**
   ```python
   for text in texts:
       analyzer.update_trends(text, ngram_range=[2, 3, 4])
   ```

3. **Reset sau m·ªói phi√™n ph√¢n t√≠ch:**
   ```python
   analyzer.reset_trends()  # Reset counter
   ```

4. **Load Vietnamese stopwords:**
   ```python
   import os
   stopwords_path = os.path.join(
       os.path.dirname(vnstock_news.__file__),
       'config', 'vietnamese-stopwords.txt'
   )
   analyzer = TrendingAnalyzer(stop_words_file=stopwords_path)
   ```

---

## 6. Roadmap & T∆∞∆°ng Lai

Module TrendingAnalyzer ƒëang ƒë∆∞·ª£c ph√°t tri·ªÉn. C√°c t√≠nh nƒÉng c√≥ th·ªÉ c√≥ trong t∆∞∆°ng lai:

- ‚úÖ N-gram phrase extraction (ƒë√£ c√≥)
- ‚è≥ Simple keyword extraction method
- ‚è≥ Time-based trending analysis  
- ‚è≥ Sentiment analysis
- ‚è≥ Multi-source comparison
- ‚è≥ Visualization helpers

---

## 7. K·∫øt Lu·∫≠n

**T√≥m t·∫Øt:**
- ‚ö†Ô∏è TrendingAnalyzer KH√îNG ƒë∆∞·ª£c export trong package ch√≠nh
- ‚ö†Ô∏è API th·ª±c t·∫ø: `update_trends()`, `get_top_trends()`, `reset_trends()`
- ‚úÖ B·∫°n c√≥ th·ªÉ t·ª± implement keyword extraction v·ªõi `Counter` ho·∫∑c `pandas`
- ‚úÖ Ho·∫∑c d√πng th∆∞ vi·ªán kh√°c nh∆∞ `sklearn.feature_extraction.text.CountVectorizer`

**Khuy·∫øn ngh·ªã:**
- S·ª≠ d·ª•ng `collections.Counter` cho keyword extraction ƒë∆°n gi·∫£n
- D√πng TrendingAnalyzer th·ª±c t·∫ø cho n-gram phrase extraction
- Tham kh·∫£o v√≠ d·ª• trong section 4 ƒë·ªÉ implement t√≠nh nƒÉng t∆∞∆°ng t·ª±
